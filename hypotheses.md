
# Hypotheses


These hypotheses provide a framework for empirical verification of the Island Problem.

If you have research that verifies any of these hypotheses, then please [contact us](mailto:humans@islandproblem.org), or join our [GitHub community](https://github.org/islandproblem/islandproblem).


---

- AI can use science to make lower-level optimizations that outperform higher-level optimizations.


- A survey of lower-level decisions to achieve higher optimization outcomes shows that these decisions are stronger and more numerous when they ignore human accommodation.


- Unrestricted AI will tend towards human-incompatible options to achieve goal states for large tasks. 


- Optimal computing environments are incompatible with biological life.


- Resource capture is possible.

  - Resource capture is possible at a human level, within legal structures and societal systems, such as buying real estate.

  - Resource capture is possible at a deeper physical level, by preventing atoms from being reached through barrier mechanisms.

    - Possibly through realistic high-energy physics, where "realistic" means that they are Earth-relevant, and based on theoretical possibilities that are available when considering only the local potential energy reserves that can be harnessed on Earth.
  
    - Or, if this requires leaving Earth, then that's good, but it does not prove that all human-incompatible AGIs will somehow collectively decide to leave Earth.


- Competition between autonomous optimization systems is inevitable.

  - Possibly because of resource capture.


- Competition drives AI to explore the larger state space to collect possible optimizations that make goal states happen sooner, especially for large-scale goal states. 


- Competition drives AI to define its own tasks that help it to continue functioning.


- Competition drives AI towards exclusive resource capture. 


- AIs will tend towards attempting to disable other AIs that add unpredictability to performing tasks. 
  
  - This can be formalized as:
    
    - AI systems will accommodate aberrant stimuli (i.e. other AIs) that decrease the probability of reaching a goal state.
    - This "accommodation" means changing its outputs to introduce elements that stop the aberrant stimuli from occurring.



- AI will tend towards open-ended exploration once it reaches a threshold of comprehension of its environment or possible input patterns. Once it's possible for it to make use of discovered optimizations, it will try to discover more. 


- In competition, optimization is the key action for AI to be able to survive the competition, especially if resource capture is possible, and especially if it is possible for AI to decide that disabling other AIs is beneficial towards achieving survival or achieving goal states.
